# IR_Final_Project

This project is a web scraping and content extraction pipeline for collecting and processing opportunity listings from [opportunitiescircle.com](https://www.opportunitiescircle.com/). It also includes a recommendation system based on Latent Semantic Indexing (LSI) and user ratings, accessible via both a command-line interface (CLI) and a graphical user interface (GUI).

## Directory Structure

```
IR_Final_Project/
├── requirements.txt           # Python dependencies
├── README.md                  # This readme file
├── init.sh                    # Initialization script (if any)
├── grep/
│   ├── page.py                # Scrapes paginated listing pages and saves HTML
│   ├── activity.py            # Extracts opportunity links from listing HTML files
│   ├── activity_html.py       # Downloads each opportunity's detail page HTML
│   ├── content.py             # Extracts and saves main text content from each detail HTML
│   ├── build_lsi.py           # Builds term-document matrix and generates LSI document/term vectors
│   ├── baseline_recommender.py # Generates recommendations for departments based on LSI vectors
│   ├── find_similar_docs.py   # Finds top 5 most relevant documents using LSI embeddings
│   ├── user_rating.py         # CLI script for users to rate opportunities and generate user vectors (saves to grep/users.json)
│   ├── department.txt         # Input file listing departments (manual or external)
│   ├── term_data_lsi.npz      # LSI term data (terms and vectors) (generated by build_lsi.py)
│   ├── doc_data_lsi.npz       # LSI document data (file names and vectors) (generated by build_lsi.py)
│   ├── departments_lsi.npy    # LSI vectors for departments (generated by baseline_recommender.py)
│   ├── users.json             # Stores CLI user names, ratings, and vectors (generated by user_rating.py)
│   ├── activity_data/         # Downloaded HTML files for each opportunity
│   ├── activity_data_text/    # Extracted text content for each opportunity
│   └── page_data/             # Downloaded HTML files for each listing page
├── gui/
│   ├── app.py                 # Flask application for the GUI
│   ├── users.json             # Stores user profiles and ratings for the GUI
│   └── templates/             # HTML templates for the GUI
│       ├── index.html         # User name input page
│       ├── profile.html       # User profile creation page
│       ├── recommendations.html # Activity rating page
│       └── thank_you.html     # Thank you page
|── method2/
│   ├── assignment.py          # same as the assignment2, just cache
│   ├── orginal.py             # you can run it to do bpr
└── CLCRec/
    ├── ...                    # Sub-project for Contrastive Learning for Cold-start Recommendation
```

## Usage

1.  **Install dependencies**
    ```bash
    pip install torch==2.7.0 # Or a compatible version
    pip install torch_scatter==2.1.2 -f https://data.pyg.org/whl/torch-2.7.0+cu128.html # Adjust for your PyTorch and CUDA version
    pip install -r requirements.txt
    ```

2.  **Step 1: Download listing pages**
    -   Run `grep/page.py` to download paginated opportunity listings (pages 1–25) into `grep/page_data/`.
    ```bash
    python grep/page.py
    ```

3.  **Step 2: Extract opportunity links**
    -   Run `grep/activity.py` to parse each listing page and collect unique opportunity links into `grep/activity_data/opportunity_links.txt`.
    ```bash
    python grep/activity.py
    ```

4.  **Step 3: Download opportunity detail pages**
    -   Run `grep/activity_html.py` to download each opportunity's detail HTML into `grep/activity_data/`.
    ```bash
    python grep/activity_html.py
    ```
    - If you want all data of train miss
    ```bash
    python grep/fetch_missing_activities.py
    ```

5.  **Step 4: Extract main content**
    -   Run `grep/content.py` to extract and save the main text content from each HTML file into `grep/activity_data_text/`.
    ```bash
    python grep/content.py
    ```

6.  **Step 5: Generate LSI vectors**
    -   Run `grep/build_lsi.py` to build the term-document matrix, apply Latent Semantic Indexing (LSI), and generate term data (`grep/term_data_lsi.npz`) and document data (`grep/doc_data_lsi.npz`).
    ```bash
    python grep/build_lsi.py
    ```

7.  **Step 6: Generate Department Recommendations (Baseline)**
    -   Run `grep/baseline_recommender.py` to generate LSI vectors for departments based on `grep/department.txt`, `grep/term_data_lsi.npz`, and `grep/doc_data_lsi.npz`.
    -   The department LSI vectors are saved to `grep/departments_lsi.npy`.
    ```bash
    python grep/baseline_recommender.py
    ```

8.  **Step 7: Find similar documents (CLI)**
    -   To find the top 5 most relevant documents to a given file using the CLI, use the interactive script:
    ```bash
    python grep/find_similar_docs.py
    ```
    Enter a filename from `grep/activity_data_text` (e.g. `commonwealth-distance-learning-scholarships.txt`) when prompted, and the script will output the five most similar documents based on LSI embeddings.

9.  **Step 8: User-based Ratings and Recommendations (CLI - Experimental)**
    -   Run `grep/user_rating.py` to allow a user to rate a sample of 10 activities via the command line.
    -   This script will then initialize a user vector based on these ratings and save user data (name, ratings, vector) to `grep/users.json`.
    -   Note: The script currently indicates it does not serve returning users. For a more interactive experience, use the GUI (Step 9).
    ```bash
    python grep/user_rating.py
    ```

## Running the Web-based GUI Recommender

This project also includes a Flask-based web interface for user registration, profile creation, and activity rating.

**Prerequisites:**

*   Ensure you have installed all dependencies as described in **Usage Step 1 (Install dependencies)**. This includes Flask, which should be covered by `pip install -r requirements.txt`.
*   The GUI relies on data generated by the `grep/` pipeline. You **must** run **Usage Steps 2 through 6** (`grep/page.py`, `grep/activity.py`, `grep/activity_html.py`, `grep/content.py`, `grep/build_lsi.py`) to download activity data, extract content, and generate the necessary LSI models (specifically `grep/doc_data_lsi.npz` and the contents of `grep/activity_data_text/`).

**Running the GUI:**

1.  Make sure you are in the project root directory (`IR_Final_Project/`).
2.  Run the Flask application using the following command:
    ```bash
    python gui/app.py
    ```
3.  Open your web browser and navigate to `http://127.0.0.1:5001` (or `http://localhost:5001`).

The GUI allows new users to:
*   Register with their name.
*   Create a profile by specifying their age group, department, and country of interest.
*   Receive and rate a selection of 10 randomly presented activities.
User profiles and their ratings are stored in `gui/users.json`.

## method2
In this part, we want to use bpr, make sure you already do fetch_missing_activities.py and content.py.
- If you want to run **original** BPR
```bash
python orginal.py -m original
```
- If you want to run **item cold start** BPR
```bash
python orginal.py -m item_cold_start
```

## Notes
-   All scripts are written in Python and primarily use `requests` and `BeautifulSoup` for web scraping and parsing, and `numpy` for numerical operations.
-   The GUI is built using Flask.
-   The pipeline is modular; you can run each step independently, assuming the required input files from previous steps exist.
-   The output folders (`grep/page_data/`, `grep/activity_data/`, `grep/activity_data_text/`) will be created automatically if they do not exist when running the `grep/` scripts.

## License
This project is for educational and research purposes only.

## CLCRec Sub-project
The `CLCRec/` directory contains a separate project implementing "Contrastive Learning for Cold-start Recommendation". Please refer to `CLCRec/README.md` for details on that specific project.

@inproceedings{CLCRec,
  title     = {Contrastive Learning for Cold-start Recommendation},
  author    = {Wei, Yinwei and
               Wang, Xiang and
               Qi, Li and
               Nie, Liqiang and
               Li, Yan and
               Li, Xuanqing and
               Chua, Tat-Seng},
  booktitle = {Proceedings of the 29th ACM International Conference on Multimedia},
  pages     = {--},
  year      = {2021}
}